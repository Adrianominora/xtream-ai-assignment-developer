{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import MyPipe as mp\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function definition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(raw_data: pd.DataFrame):\n",
    "    data = raw_data.loc[(raw_data.x * raw_data.y * raw_data.z != 0) & (raw_data.price > 0)] # Clean zero dimensions and negative prices\n",
    "    data = data.drop(columns=['depth', 'table', 'y', 'z']) # Drop not usefull columns\n",
    "    data_dummy = pd.get_dummies(data, columns=['cut', 'color', 'clarity'], drop_first=True) # Compute dummies columns\n",
    "    return data_dummy\n",
    "\n",
    "def split_data(data: pd.DataFrame, test_size=0.2, random_state=42, apply_ylog = False):\n",
    "    x = data.drop(columns='price')\n",
    "    y = data.price\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=test_size, random_state=random_state)\n",
    "    if (apply_ylog):\n",
    "        y_train = np.log(y_train)\n",
    "        y_test = np.log(y_test)\n",
    "    return x_train, x_test, y_train, y_test\n",
    "    \n",
    "def plot_gof(y_true: pd.Series, y_pred: pd.Series):\n",
    "    plt.plot(y_true, y_pred, '.')\n",
    "    plt.plot(y_true, y_true, linewidth=3, c='black')\n",
    "    plt.xlabel('Actual')\n",
    "    plt.ylabel('Predicted')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C1.1 Example on how to use the class MyPipe with the whole dataset (no data acquisition)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diamonds = pd.read_csv(\"https://raw.githubusercontent.com/xtreamsrl/xtream-ai-assignment-engineer/main/datasets/diamonds/diamonds.csv\")\n",
    "\n",
    "data = preprocess_data(diamonds)\n",
    "x_train, x_test, y_train, y_test = split_data(data, apply_ylog=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline = mp.MyPipe()\n",
    "my_pipeline.define_data(data)\n",
    "my_pipeline.fit(x_train,y_train)\n",
    "\n",
    "pred = my_pipeline.predict(x_test)\n",
    "performance = my_pipeline.evaluate_performance(np.exp(y_test), np.exp(pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_gof(np.exp(y_test), np.exp(pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C1.2 Simulate data acquisition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "half = int(len(data.index)/2)\n",
    "data0 = data[:half] # Suppose we know half of the data at the beginning of the procedure\n",
    "batch_size = 100 #Number of new diamonds in each batch of new data\n",
    "data_new = [] # List of the data coming in batch at every update\n",
    "i = 0\n",
    "while (half+batch_size*(i+1)<len(data.index)):\n",
    "    data_new.append(data[half+batch_size*i:half+batch_size*(i+1)])\n",
    "    i +=1\n",
    "data_new.append(data[half+batch_size*i:])\n",
    "\n",
    "# Define the first model with half of the data\n",
    "x_train, x_test, y_train, y_test = split_data(data0, apply_ylog=True)\n",
    "\n",
    "my_pipeline = mp.MyPipe()\n",
    "my_pipeline.define_data(data0)\n",
    "my_pipeline.fit(x_train,y_train)\n",
    "\n",
    "pred = my_pipeline.predict(x_test)\n",
    "performance = my_pipeline.evaluate_performance(np.exp(y_test), np.exp(pred))\n",
    "my_pipeline.dump('../data/models_history/linear_model/lin_0.pkl') # save the pipeline to file\n",
    "\n",
    "for n, current_data in enumerate(data_new):\n",
    "    print(f'Batch {n+1} of {len(data_new)}')\n",
    "    my_pipeline.augment_data(current_data)\n",
    "    x_train, x_test, y_train, y_test = split_data(my_pipeline.data, apply_ylog=True)\n",
    "    my_pipeline.fit(x_train, y_train)\n",
    "    pred = my_pipeline.predict(x_test)\n",
    "    performance = my_pipeline.evaluate_performance(np.exp(y_test), np.exp(pred))\n",
    "    my_pipeline.dump(f'../data/models_history/linear_model/lin_{n+1}.pkl') # save the pipeline to file\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_pipeline.plot_history(trendline=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
